{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sigmoid\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rule\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def relu_derivative(x):\n",
    "    return np.where(x > 0, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize data for XOR problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "y = np.array([[0], [1], [1], [0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "input_size = 2\n",
    "hidden_size = 4\n",
    "output_size = 1\n",
    "learning_rate = 0.1\n",
    "epochs = 10000\n",
    "\n",
    "W1 = np.random.randn(input_size, hidden_size) # 2X4\n",
    "b1 = np.zeros((1, hidden_size)) # 1X4\n",
    "W2 = np.random.randn(hidden_size, output_size) #4X1\n",
    "b2 = np.zeros((1, output_size)) # 1X1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Traininig loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    # Forward Propagation\n",
    "    Z1 = np.dot(X, W1) + b1\n",
    "    A1  = relu(Z1)\n",
    "    Z2 = np.dot(A1, W2) + b2\n",
    "    A2  = sigmoid(Z2)\n",
    "\n",
    "    # Compute Loss (Binary Cross-Entropy)\n",
    "    loss = -np.mean(y * np.log(A2) + (1 - y) * np.log(1 - A2))\n",
    "\n",
    "    # Backpropagation\n",
    "    dA2 = A2 - y\n",
    "    dZ2 = dA2 * sigmoid_derivative(A2)\n",
    "    dW2 = np.dot(A1.T, dZ2)\n",
    "    db2 = np.sum(dZ2, axis=0, keepdims=True)\n",
    "\n",
    "    dA1 = np.dot(dZ2, W2.T)\n",
    "    dZ1 = dA1 * relu_derivative(Z1)\n",
    "    dW1 = np.dot(X.T, dZ1)\n",
    "    db1 = np.sum(dZ1, axis=0, keepdims=True)\n",
    "\n",
    "    # Update Parameters\n",
    "    W1 -= learning_rate * dW1\n",
    "    b1 -= learning_rate * db1\n",
    "    W2 -= learning_rate * dW2\n",
    "    b2 -= learning_rate * db2\n",
    "\n",
    "    # Print loss every 1000 epochs\n",
    "    if epoch % 100 == 0:\n",
    "        \"\"\" print(f\"Epoch {epoch}, W1: {W1}\")\n",
    "        print(f\"Epoch {epoch}, b1: {b1}\")\n",
    "        print(f\"Epoch {epoch}, W2: {W2}\")\n",
    "        print(f\"Epoch {epoch}, b2: {b2}\") \"\"\"\n",
    "        \n",
    "        print(f\"Epoch {epoch}, Loss: {loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Model\n",
    "predictions = A2 > 0.5\n",
    "accuracy = np.mean(predictions == y)\n",
    "print(f\"Final Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
